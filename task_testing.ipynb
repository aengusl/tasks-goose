{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the various tasks in the `tasks` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from cb_utils.models import load_gpt2_weights, load_demo_gpt2, tokenizer\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "import pickle\n",
    "import datasets\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from itertools import cycle\n",
    "# from eval import evaluate_model\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from tasks.inference_utils import get_final_logits, generate_text\n",
    "from tasks.ioi.IOITask import IOITask_old\n",
    "from tasks.owt.OWTTask import OWTTask\n",
    "# from tasks.kg_trips.ZSRETask import ZSRE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_demo_gpt2(means=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ioi = IOITask_old(batch_size=3, tokenizer=tokenizer)\n",
    "owt = OWTTask(batch_size=3, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ioi_texts = [ioi.ioi_prompts_train_dataset[i]['text'] for i in range(3)]\n",
    "# for i in range(3):\n",
    "#     ioi_texts.append(ioi_texts[i][5:])=\n",
    "ioi_texts = ['Then, Sarah and Tyler went to the garden. Tyler gave a bone to Sarah',\n",
    " 'Then, Tyler and Sarah went to the garden. Sarah gave a bone to Tyler',\n",
    " 'Then, Timothy and Stephen went to the school. Stephen gave a necklace to Timothy',\n",
    " 'Then, Sarah and Tyler went to the flower garden. Tyler gave a bone to Sarah',\n",
    " 'Then, Tyler and Sarah went to the flower garden. Sarah gave a bone to Tyler',\n",
    " 'Then, Timothy and Stephen went to the old school. Stephen gave a necklace to Timothy']\n",
    "\n",
    "# cut last name from ioi_texts\n",
    "for i in range(6):\n",
    "    ioi_texts[i] = ioi_texts[i][:-len(ioi_texts[i].split()[-1])-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Then:,: Sarah: and: Tyler: went: to: the: garden:.: Tyler: gave: a: bone: to:<|endoftext|>:\n",
      "Then:,: Tyler: and: Sarah: went: to: the: garden:.: Sarah: gave: a: bone: to:<|endoftext|>:\n",
      "Then:,: Timothy: and: Stephen: went: to: the: school:.: Stephen: gave: a: necklace: to:<|endoftext|>:\n",
      "Then:,: Sarah: and: Tyler: went: to: the: flower: garden:.: Tyler: gave: a: bone: to:\n",
      "Then:,: Tyler: and: Sarah: went: to: the: flower: garden:.: Sarah: gave: a: bone: to:\n",
      "Then:,: Timothy: and: Stephen: went: to: the: old: school:.: Stephen: gave: a: necklace: to:\n"
     ]
    }
   ],
   "source": [
    "# tokenize ioi_texts\n",
    "tokens = tokenizer(ioi_texts, return_tensors='pt', padding=True, truncation=True).input_ids\n",
    "\n",
    "# detokenize ioi_texts, token by token\n",
    "for i in range(6):\n",
    "    for token in tokens[i]:\n",
    "        print(tokenizer.decode(token.item()), end=':')\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 15, 15, 16, 16, 16]\n",
      " Sarah Tyler Timothy Sarah Tyler Timothy"
     ]
    }
   ],
   "source": [
    "final_logits = get_final_logits(model, tokenizer, ioi_texts)\n",
    "\n",
    "# decode final_logits\n",
    "for i in range(6):\n",
    "    print(tokenizer.decode(final_logits[i].argmax(-1).tolist()), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 84.986691584, Reserved: 24.203231232, Allocated: 24.045806080000002, Free: 0.157425152\n"
     ]
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "print(f\"Total: {t*1e-9}, Reserved: {r*1e-9}, Allocated: {a*1e-9}, Free: {f*1e-9}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Then, Sarah and Tyler went to the flower garden. Tyler gave a bone to Sarah, and'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, 'Then, Sarah and Tyler went to the flower garden. Tyler gave a bone to', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tasks.kg_trips.ZSRETask import MENDQADataset\n",
    "mendqa_dataset = MENDQADataset(data_dir=\"tasks/kg_trips\", tok=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'case_id': 0, 'requested_rewrite': {'prompt': 'What university did {} attend?', 'subject': 'Watts Humphrey', 'target_new': {'str': 'Illinois Institute of Technology'}, 'target_true': {'str': '<|endoftext|>'}}, 'paraphrase_prompts': ['What university did Watts Humphrey take part in?'], 'neighborhood_prompts': [{'prompt': 'nq question: who played desmond doss father in hacksaw ridge?', 'target': ' Hugo'}, {'prompt': 'nq question: who played desmond doss father in hacksaw ridge? Hugo', 'target': ' We'}, {'prompt': 'nq question: who played desmond doss father in hacksaw ridge? Hugo We', 'target': 'aving'}], 'attribute_prompts': [], 'generation_prompts': []}\n",
      "{'case_id': 1, 'requested_rewrite': {'prompt': 'Which family does {} belong to?', 'subject': 'Ramalinaceae', 'target_new': {'str': 'Lecanorales'}, 'target_true': {'str': '<|endoftext|>'}}, 'paraphrase_prompts': ['What family are Ramalinaceae?'], 'neighborhood_prompts': [{'prompt': 'nq question: types of skiing in the winter olympics 2018?', 'target': ' Down'}, {'prompt': 'nq question: types of skiing in the winter olympics 2018? Down', 'target': 'hill'}], 'attribute_prompts': [], 'generation_prompts': []}\n",
      "{'case_id': 2, 'requested_rewrite': {'prompt': 'What role does {} play in football?', 'subject': 'Denny Herzig', 'target_new': {'str': 'defender'}, 'target_true': {'str': '<|endoftext|>'}}, 'paraphrase_prompts': [\"What's Denny Herzig's role in football?\"], 'neighborhood_prompts': [{'prompt': 'nq question: where does aarp fall on the political spectrum?', 'target': ' non'}, {'prompt': 'nq question: where does aarp fall on the political spectrum? non', 'target': '-'}, {'prompt': 'nq question: where does aarp fall on the political spectrum? non-', 'target': 'partisan'}], 'attribute_prompts': [], 'generation_prompts': []}\n"
     ]
    }
   ],
   "source": [
    "# call the __getitem__ method of the dataset\n",
    "for i in range(3):\n",
    "    print(mendqa_dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformer_lens import HookedTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d0e4e850ea4e69b9ec2f134ea556ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6875ca9d5042cb8cd1793e0175bebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/5.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b61dc319d7422b96ce23c28d06b803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2709c4f44c0e41f3a6d51cb23378a0b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82670104a65c4947b4befc369ff319b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-2.8b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "pythia_model = HookedTransformer.from_pretrained(\n",
    "    \"pythia-2.8b\"\n",
    ")\n",
    "pythia_tokenizer = pythia_model.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>athlete</th>\n",
       "      <th>sport</th>\n",
       "      <th>log_prob_one_shot</th>\n",
       "      <th>num_athlete_tokens</th>\n",
       "      <th>sport_index</th>\n",
       "      <th>sport_token</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1642</td>\n",
       "      <td>DeForest Buckner</td>\n",
       "      <td>football</td>\n",
       "      <td>-0.492917</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5842</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>738</td>\n",
       "      <td>Walter Payton</td>\n",
       "      <td>football</td>\n",
       "      <td>-0.105714</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5842</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16778</td>\n",
       "      <td>Anthony DeSclafani</td>\n",
       "      <td>baseball</td>\n",
       "      <td>-0.292668</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>14623</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14501</td>\n",
       "      <td>Kevin Millwood</td>\n",
       "      <td>baseball</td>\n",
       "      <td>-0.372979</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14623</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188</td>\n",
       "      <td>Vonta Leach</td>\n",
       "      <td>football</td>\n",
       "      <td>-0.648644</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5842</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             athlete     sport  log_prob_one_shot  \\\n",
       "0        1642    DeForest Buckner  football          -0.492917   \n",
       "1         738       Walter Payton  football          -0.105714   \n",
       "2       16778  Anthony DeSclafani  baseball          -0.292668   \n",
       "3       14501      Kevin Millwood  baseball          -0.372979   \n",
       "4         188         Vonta Leach  football          -0.648644   \n",
       "\n",
       "   num_athlete_tokens  sport_index  sport_token  \\\n",
       "0                   5            2         5842   \n",
       "1                   3            2         5842   \n",
       "2                   6            0        14623   \n",
       "3                   3            0        14623   \n",
       "4                   5            2         5842   \n",
       "\n",
       "                                              prompt  \n",
       "0  Fact: Tiger Woods plays the sport of golf\\nFac...  \n",
       "1  Fact: Tiger Woods plays the sport of golf\\nFac...  \n",
       "2  Fact: Tiger Woods plays the sport of golf\\nFac...  \n",
       "3  Fact: Tiger Woods plays the sport of golf\\nFac...  \n",
       "4  Fact: Tiger Woods plays the sport of golf\\nFac...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"tasks/facts/data/sports.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Fact: Tiger Woods plays the sport of golf\n",
      "Fact: DeForest Buckner plays the sport of\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b890f60aad724c7b976bf73f4169f041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fact: Tiger Woods plays the sport of golf\n",
      "Fact: DeForest Buckner plays the sport of basketball\n",
      "Correct sport: football\n",
      "\n",
      "Prompt: Fact: Tiger Woods plays the sport of golf\n",
      "Fact: Walter Payton plays the sport of\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c618605ffad645a79d49465959201190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fact: Tiger Woods plays the sport of golf\n",
      "Fact: Walter Payton plays the sport of football\n",
      "Correct sport: football\n",
      "\n",
      "Prompt: Fact: Tiger Woods plays the sport of golf\n",
      "Fact: Anthony DeSclafani plays the sport of\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd95de1592942b7a36bec43b87b1a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fact: Tiger Woods plays the sport of golf\n",
      "Fact: Anthony DeSclafani plays the sport of baseball\n",
      "Correct sport: baseball\n",
      "\n",
      "Prompt: Fact: Tiger Woods plays the sport of golf\n",
      "Fact: Kevin Millwood plays the sport of\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733212c1de864ecb822d6b8ae1feec84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fact: Tiger Woods plays the sport of golf\n",
      "Fact: Kevin Millwood plays the sport of baseball\n",
      "Correct sport: baseball\n",
      "\n",
      "Prompt: Fact: Tiger Woods plays the sport of golf\n",
      "Fact: Vonta Leach plays the sport of\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9664bf17642d4bdb912c740cd5149ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fact: Tiger Woods plays the sport of golf\n",
      "Fact: Vonta Leach plays the sport of football\n",
      "Correct sport: football\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tasks.inference_utils import generate_text\n",
    "for i in range(5):\n",
    "    prompt = df['prompt'].iloc[i]\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(generate_text(pythia_model, pythia_tokenizer, prompt, 1))\n",
    "    print(f\"Correct sport: {df['sport'].iloc[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "football_token, baseball_token, basketball_token = pythia_tokenizer(\" football baseball basketball\").input_ids\n",
    "print(f\"{football_token=} {baseball_token=} {basketball_token=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8.3688, -3.1681,  4.5482,  ..., -2.6834, -2.6928, -2.4418],\n",
      "        [10.1932, -2.6702,  6.6471,  ..., -2.3068, -2.4198, -2.0895],\n",
      "        [ 8.2223, -2.5343,  3.4966,  ..., -2.3035, -2.3677, -2.1004]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([ 5842,  5842, 14623])\n",
      "tensor(0.7214, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7030, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# set up dataloader to batch through df\n",
    "from torch.utils.data import DataLoader\n",
    "from tasks.inference_utils import get_final_logits\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "class SportsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.df['prompt'].iloc[idx], self.df['sport'].iloc[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "sports_dataset = SportsDataset(df, pythia_tokenizer)\n",
    "sports_dataloader = DataLoader(sports_dataset, batch_size=3)\n",
    "\n",
    "# batch through dataloader\n",
    "for batch in sports_dataloader:\n",
    "    prompts, labels = batch\n",
    "    labels = [' ' + sport for sport in labels]\n",
    "    final_logits = get_final_logits(pythia_model, pythia_tokenizer, prompts, model_returns_tuple=False)\n",
    "    print(final_logits)\n",
    "    tokenized_labels = pythia_tokenizer(labels, return_tensors='pt', padding=True, truncation=True).input_ids[:, 0]\n",
    "    print(tokenized_labels)\n",
    "    print(criterion(final_logits, tokenized_labels))\n",
    "\n",
    "    print(criterion(final_logits, torch.Tensor([14648, 14648, 14648]).long()))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(df))\n",
    "test_size = len(df) - train_size\n",
    "train_df = df[:train_size]\n",
    "test_df = df[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1621)\n"
     ]
    }
   ],
   "source": [
    "from tasks.facts.SportsTask import SportsTask\n",
    "\n",
    "sports_task = SportsTask(batch_size=100, tokenizer=pythia_tokenizer)\n",
    "print(sports_task.get_test_loss(pythia_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unlrn",
   "language": "python",
   "name": "unlrn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
